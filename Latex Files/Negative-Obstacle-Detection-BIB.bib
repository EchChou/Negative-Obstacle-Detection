@article{Abdi2010,
abstract = {Principal component analysis (PCA) is a multivariate technique that analyzes a data table in which observations are described by several inter-correlated quantitative dependent variables. Its goal is to extract the important information from the table, to represent it as a set of new orthogonal variables called principal components, and to display the pattern of similarity of the observations and of the variables as points in maps. The quality of the PCA model can be evaluated using cross-validation techniques such as the bootstrap and the jackknife. PCA can be generalized as correspondence analysis (CA) in order to handle qualitative variables and as multiple factor analysis (MFA) in order to handle heterogeneous sets of variables. Mathematically, PCA depends upon the eigen-decomposition of positive semideﬁnite matrices and upon the singular value decomposition (SVD) of rectangular matrices},
author = {Abdi, H. and Williams, L.J.},
journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
keywords = {PCA},
title = {{Principle component analysis}},
year = {2010}
}
@misc{Calder1990,
author = {Calder, Jill C. and Kirby, Lee R.},
file = {:C$\backslash$:/Users/tbaum/Downloads/poo.pdf:pdf},
keywords = {Accidents,Protective Devices,Rehabilitation,Safety,Wheelchairs},
pages = {184--190},
publisher = {American Journal of Physical Medicine {\&} Rehabilitation},
title = {{Fatal wheelchair related accidents in the US.pdf}},
year = {1990}
}
@article{Xiang2006,
author = {Xiang, H and Chany, A-M and Smith, G A},
doi = {10.1136/ip.2005.010033},
file = {:C$\backslash$:/Users/tbaum/Downloads/8.full.pdf:pdf},
issn = {1353-8047},
journal = {Injury Prevention},
number = {1},
pages = {8--11},
title = {{Wheelchair related injuries treated in US emergency departments}},
url = {http://injuryprevention.bmj.com/cgi/doi/10.1136/ip.2005.010033},
volume = {12},
year = {2006}
}
@article{Jipp2012,
abstract = {Objective: The extent to which individual differences in fine motor abilities affect indoor safety and efficiency of human-wheelchair systems was examined.Background: To reduce the currently large number of indoor wheelchair accidents, assistance systems with a high level of automation were developed. It was proposed to adapt the wheelchair's level of automation to the user's ability to steer the device to avoid drawbacks of highly automated wheelchairs. The state of the art, however, lacks an empirical identification of those abilities.Method: A study with 23 participants is described. The participants drove through various sections of a course with a powered wheelchair. Repeatedly measured criteria were safety (numbers of collisions) and efficiency (times required for reaching goals). As covariates, the participants' fine motor abilities were assessed.Results: A random coefficient modeling approach was conducted to analyze the data, which were available on two levels as course sections were nested within participants. The participants' aiming, precision, and arm–hand speed contributed significantly to both criteria: Participants with lower fine motor abilities had more collisions and required more time for reaching goals.Conclusion: Adapting the wheelchair's level of automation to these fine motor abilities can improve indoor safety and efficiency. In addition, the results highlight the need to further examine the impact of individual differences on the design of automation features for powered wheelchairs as well as other applications of automation.Application: The results facilitate the improvement of current wheelchair technology. },
author = {Jipp, Meike},
doi = {10.1177/0018720812443826},
file = {:C$\backslash$:/Users/tbaum/Downloads/good shit.pdf:pdf},
issn = {0018-7208},
journal = {Human Factors: The Journal of the Human Factors and Ergonomics Society },
keywords = {action,address correspondence to meike,assistance systems,fine motor abilities,human,jipp,level of automation,level regression model,machine inter-,multi-,random coefficient modeling},
number = {6 },
pages = {1075--1086},
pmid = {23397815},
title = {{Individual Differences and Their Impact on the Safety and the Efficiency of Human-Wheelchair Systems}},
url = {http://hfs.sagepub.com/content/54/6/1075.abstract},
volume = {54 },
year = {2012}
}
@article{Wolpaw2007,
abstract = {Brain-computer interfaces (BCIs) can provide non-muscular communication and control for people with severe motor disabilities. Current BCIs use a variety of invasive and non-invasive methods to record brain signals and a variety of signal processing methods. Whatever the recording and processing methods used, BCI performance (e.g. the ability of a BCI to control movement of a computer cursor) is highly variable and, by the standards applied to neuromuscular control, could be described as ataxic. In an effort to understand this imperfection, this paper discusses the relevance of two principles that underlie the brain's normal motor outputs. The first principle is that motor outputs are normally produced by the combined activity of many CNS areas, from the cortex to the spinal cord. Together, these areas produce appropriate control of the spinal motoneurons that activate muscles. The second principle is that the acquisition and life-long preservation of motor skills depends on continual adaptive plasticity throughout the CNS. This plasticity optimizes the control of spinal motoneurons. In the light of these two principles, a BCI may be viewed as a system that changes the outcome of CNS activity from control of spinal motoneurons to, instead, control of the cortical (or other) area whose signals are used by the BCI to determine the user's intent. In essence, a BCI attempts to assign to cortical neurons the role normally performed by spinal motoneurons. Thus, a BCI requires that the many CNS areas involved in producing normal motor actions change their roles so as to optimize the control of cortical neurons rather than spinal motoneurons. The disconcerting variability of BCI performance may stem in large part from the challenge presented by the need for this unnatural adaptation. This difficulty might be reduced, and BCI development might thereby benefit, by adopting a 'goal-selection' rather than a 'process- control' strategy. In 'process control', a BCI manages all the intricate high-speed interactions involved in movement. In 'goal selection', by contrast, the BCI simply communicates the user's goal to software that handles the high-speed interactions needed to achieve the goal. Not only is 'goal selection' less demanding, but also, by delegating lower-level aspects of motor control to another structure (rather than requiring that the cortex do everything), it more closely resembles the distributed operation characteristic of normal motor control.},
author = {Wolpaw, Jonathan R.},
doi = {10.1113/jphysiol.2006.125948},
file = {:C$\backslash$:/Users/tbaum/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wolpaw - 2007 - Brain-computer interfaces as new brain output pathways.pdf:pdf},
isbn = {0022-3751},
issn = {00223751},
journal = {The Journal of Physiology},
number = {3},
pages = {613--619},
pmid = {17255164},
title = {{Brain-computer interfaces as new brain output pathways}},
url = {http://doi.wiley.com/10.1113/jphysiol.2006.125948},
volume = {579},
year = {2007}
}
@article{Kim2013,
abstract = {Purpose Highly disable patients, who use the powered wheelchair, require an autonomous wheelchair for movement. Fundamental problem of the autonomous wheelchairs is safety. In order to dodge the obstacles, efficient searching method of the obstacles is necessary. Methods The proposed method utilizes multiple ultrasound emitters that generate signals of identical frequency and intensity. Corresponding sensors detect the reflected ultrasound signals, and the position of the obstacle is calculated based on the time of flight (TOF) of the ultrasound wave. It was carried out the obstacle searching experiments with proposed method. Results The results showed that the proposed method's errors are within 1{\~{}}2{\%} which is much lesser than the general scan method. Therefore, the proposed method is suitable for autonomous wheelchairs as it facilitates detection of the nearest obstacle, and yields more accurate estimation of the position. Conclusions Therefore, the proposed method based on a simultaneous emission strategy is suitable for autonomous wheelchairs as it facilitates detection of the nearest obstacle, and yields more accurate estimation of the position.},
annote = {FINAL CONCLUSION


GENERAL NOTES

- Justifies the use of ultrasonic sensors simultaneously by introducing a method with errors within 1-2{\%}
- Details the angular depiction of detection covered by ultrasonic sensors and the mathmatics behind how specific distances between the obstacles and the sensors are calculated
- Only utilizes sensors in the front of the wheelchair
- However, the errors still stayed within 2{\%} for the simultaneous emission method, while the scan method yielded generally larger errors, with some sensors showing much larger error},
author = {Kim, Chang Geol and Song, Byung Seop},
doi = {10.1007/s13534-013-0088-9},
file = {:C$\backslash$:/Users/tbaum/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim, Song - 2013 - Proposal of a simultaneous ultrasound emission for efficient obstacle searching in autonomous wheelchairs.pdf:pdf},
issn = {2093985X},
journal = {Biomedical Engineering Letters},
keywords = {Autonomous wheelchair,Rehabilitation,Simultaneous emission,Ultrasound},
number = {1},
pages = {47--50},
title = {{Proposal of a simultaneous ultrasound emission for efficient obstacle searching in autonomous wheelchairs}},
volume = {3},
year = {2013}
}
@article{Nguyen2007,
abstract = {This paper is concerned with the development of a real-time obstacle avoidance system for an autonomous wheelchair using stereoscopic cameras by severely disabled people. Based on the left and right images captured from stereoscopic cameras mounted on the wheelchair, the optimal disparity is computed using the Sum of Absolute Differences (SAD) correlation method. From this disparity, a 3D depth map is constructed based on a geometric projection algorithm. A 2D map converted from this 3D map can then be employed to provide an effective obstacle avoidance strategy for this wheelchair. Experiment results obtained in a practical environment show the effectiveness of this real-time implementation.},
annote = {FINAL CONCLUSIONS


GENERAL NOTES

- This paper implements the use of a stereoscopic
camera in order to detect positive obstacles. From this camera, using the sum
of absolute difference method, and stereo disparity map is created. This map
can then be translated into a 3D point cloud image which is generated with
sub-pixel interpolation. This creates a more accurate stereo depth extraction.
From this, a 2D distance map is then created. This is the main graph used for
the obstacle detection algorithm implemented. 
 

- There is insufficient description of the actual
implementation of the method in real time. Effectiveness is claimed, and there
is evidence of accurate obstacle detection, however there is no evidence of
actual obstacle avoidance. However, the main point of the paper is the
transition from a 3D disparity map from the stereoscopic camera, so the lack of
evidence of obstacle avoidance does not invalidate the paper. 
 

- To create the 3D disparity map, they used an
existing program, the Point-Grey Research (PGR) software, to detect distances.
From the stereoscopic camera, a picture is created where the colder colors represent
objects that are far away and the hotter colors represent objects that are closer.
The picture is then separated into 38 columns. Each column is then scanned to
find the closest component, and these values are used to determine the closest
object in each segment. 
 

- The camera can only see in front of it; there is
no visibility surrounding the entire wheelchair. 
 

- The methodology seemed sound with this avoidance
method, but it is not explained sufficiently to warrant extreme focus on the
methods used. Concepts that stand out only apply to positive obstacles. The
angles used with the camera would be insufficient for negative obstacles.





:�� �. �},
author = {Nguyen, Thanh and Nguyen, Jordan S. and Pham, Duc and Nguyen, Hung T.},
file = {:C$\backslash$:/Users/tbaum/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen et al. - 2007 - Real-Time Obstacle Detection for an Autonomous Wheelchair Using Stereoscopic Cameras.pdf:pdf},
isbn = {1424407885},
journal = {IEEE Conference},
pages = {4775--4778},
title = {{Real-Time Obstacle Detection for an Autonomous Wheelchair Using Stereoscopic Cameras}},
year = {2007}
}
@article{Castillo2006,
abstract = {An advanced prototype Computer Controlled Power Wheelchair Navigation System or CCPWNS has been developed to provide autonomy for highly disabled users, whose mix of disabilities makes it difficult or impossible to control their own power chairs in their homes. The working paradigm is “teach and repeat” a mode of control for typical industrial holonomic robots. Ultrasound sensors, which during subsequent autonomous tracking will be used to detect obstacles, also are active during teaching. Based upon post-processed data collected during this teaching event, elaborate trajectories – which may involve multiple direction changes, pivoting and so on, depending upon the requirements of the typically restricted spaces within which the chair must operate – will later be called upon by the disabled rider. An off-line postprocessor assigns an ultrasound profile to the sequence of poses of any taught trajectory. Use of this profile during tracking obviates most of the inherent problems of using ultrasound to avoid obstacles while retaining the ability to near solid objects, such as when passing through a narrow doorway, where required by the environment and trajectory objectives. The work in this article describes a procedure to obtain consistent maps of sonar boundaries during the teaching process, and a preliminary approach to use this information during the tracking phase. The approach is illustrated by results obtained by using the CCPWNS prototype.},
annote = {FINAL CONCLUSIONS


GENERAL NOTES
The paper implements the use of ultrasonic
sensors (like our PING sensors) for its obstacle detection. It justifies the
applicability of sonar to obstacle detection specifically for a wheelchair.
While the data received from ultrasonic sensors is coarse, it is also
consistent, and consistency is the main component for a safe a reliable
vehicle. Ultrasonic sensors are less sensitive to noise, unlike LiDARS, and the
matching of patterns of detection is easier to achieve. 
      
An issues that comes with ultrasonic sensors is that, when the sensor hits the same point at different angles, the distance of
the obstacle from the sensor appears to change. This is because the distance
from the wall to the sensor remains constant regardless of the differing angle
of the sensor to the wall. This paper focused mostly on the characterization of
these errors due to the sonar's functionality in order to allow for more accurate
obstacle avoidance. 

This method focuses on a wheelchair that would only be implemented in an enclosed space where it (the wheelchair) was aware of
the surroundings initially through a “teaching episode” (like in the user's
home). This severely limits the user, even though the point of creating an
autonomous wheelchair is to increase mobility and quality of life. One of the
main reasons that sonar is used in this paper is because the data is used as a
general guide to areas that differ from the original data acquired by the
teaching episode. It is not the main means of obstacle detection. 
     
Keeping the previous point in mind, the
ultrasonic readings need to be further refined in order to sufficiently
function as the main means of obstacle detection in dynamic environments that
the wheelchair is not familiar with; or we must implement another technique in
addition to the ultrasonic sensors.

This paper also tackles a common issue with
obstacle detection for wheelchairs – doorways. It effectively entered through a
doorway 15 times, and avoided an obstacle placed in front of an obstacle 5
times.},
author = {Castillo, Guillermo Del and Skaar, Steven and Cardenas, Antonio and Fehr, Linda},
doi = {10.1016/j.robot.2006.05.011},
file = {:C$\backslash$:/Users/tbaum/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Castillo et al. - 2006 - A sonar approach to obstacle detection for a vision-based autonomous wheelchair.pdf:pdf},
journal = {Elsevier},
keywords = {control systems,estimation using vision,robotics,sonar obstacle detection,wheeled robots},
pages = {967--981},
title = {{A sonar approach to obstacle detection for a vision-based autonomous wheelchair}},
volume = {54},
year = {2006}
}
@article{Xiao2015,
abstract = {The ability to follow or move alongside a person is a necessary skill for an autonomous mo- bile agent that works with human users. To accomplish such tasks, we develop a new scheme of visual- target detection and tracking for a wheelchair robot equipped with Microsoft Kinect that captures RGB images along with per-pixel depth information (RGB-D camera). The speeded-up semi-supervised on- line boosting algorithm is employed to provide the robust description of feature for environments and the target person from RGB images. Based on the environmental Haar-like features, we utilize an ex- tended Kalman filter (EKF) based localization to estimate robot pose. Then obstacle avoidance naviga- tion approach based on $\eta$3 spline trajectory planning and optimization are proposed for the wheelchair robot. Finally, the experimental results are provided to demonstrate the effectiveness and feasibility in real world environments.},
author = {Xiao, Hanzhen and Li, Zhijun and Yang, Chenguang and Yuan, Wang and Wang, Liyang},
doi = {10.1007/s12555-014-0353-4},
file = {:C$\backslash$:/Users/tbaum/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Xiao et al. - 2015 - RGB-D sensor-based visual target detection and tracking for an intelligent wheelchair robot in indoors environments.pdf:pdf},
isbn = {1561000248},
issn = {20054092},
journal = {International Journal of Control, Automation and Systems},
keywords = {Intelligent wheelchair,obstacle avoidance,vision tracking},
number = {3},
pages = {521--529},
title = {{RGB-D sensor-based visual target detection and tracking for an intelligent wheelchair robot in indoors environments}},
volume = {13},
year = {2015}
}
@article{Lee2016,
abstract = {This paper presents a monocular vision sensor-based obstacle detection algorithm for autonomous robots. Each individual image pixel at the bottom region of interest is labeled as belonging either to an obstacle or the floor. While conventional methods depend on point tracking for geometric cues for obstacle detection, the proposed algorithm uses the inverse perspective mapping (IPM) method. This method is much more advantageous when the camera is not high off the floor, which makes point tracking near the floor difficult. Markov random field-based obstacle segmentation is then performed using the IPM results and a floor appearance model. Next, the shortest distance between the robot and the obstacle is calculated. The algorithm is tested by applying it to 70 datasets, 20 of which include nonobstacle images where considerable changes in floor appearance occur. The obstacle segmentation accuracies and the distance estimation error are quantitatively analyzed. For obstacle datasets, the segmentation precision and the average distance estimation error of the proposed method are 81.4{\%} and 1.6 cm, respectively, whereas those for a conventional method are 57.5{\%} and 9.9 cm, respectively. For nonobstacle datasets, the proposed method gives 0.0{\%} false positive rates, while the conventional method gives 17.6{\%}.},
author = {Lee, Tae-jae and Yi, Dong-hoon and Cho, Dong-il Dan},
doi = {10.3390/s16030311},
file = {:C$\backslash$:/Users/tbaum/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee, Yi, Cho - 2016 - A Monocular Vision Sensor-Based Obstacle Detection Algorithm for Autonomous Robots.pdf:pdf},
journal = {Sensors},
keywords = {monocular vision,obstacle detection,segmentation},
number = {311},
pages = {1--20},
title = {{A Monocular Vision Sensor-Based Obstacle Detection Algorithm for Autonomous Robots}},
volume = {16},
year = {2016}
}
@article{Nguyen2013,
abstract = {In this paper, an advanced obstacle avoidance system is developed for an intelligent wheelchair designed to support people with mobility impairments who also have visual, upper limb, or cognitive impairment. To avoid obstacles, immediate environment information is continuously updated with range data sampled by an on-board laser range finder URG-04LX. Then, the data is transformed to find the relevant information to the navigating process before being presented to a trained obstacle avoidance neural network which is optimized under the supervision of a Bayesian framework to find its structure and weight values. The experiment results showed that this method allows the wheelchair to avoid collisions while simultaneously navigating through an unknown environment in real-time. More importantly, this new approach significantly enhances the performance of the system to pass narrow openings such as door passing.},
annote = {FINAL CONCLUSION

GENERAL NOTES

- Focuses to find a path that is circumnavigable with attention to door openings. In particular, the wheelchair calculates the size of a path opening, if the size is greater than the vehicle's width size plus a safe margin, the path is considered as one of potential paths of travel.
- Depicts how the wheelchair's would be altered in the event of an obstacle. For example (In contrast, when moving between two closely spaced obstacles such as the posts of a doorway, the wheelchair is slowed down, and centered with the doorway – the maximum speed for passing door task is only set at 0.5 m/s. In this situation, a slight difference between a steering angle and the desired direction is usually acceptable.)
- Generally describes the process behind the navigation method. To avoid obstacles, immediate environment information is continuously updated with range data sampled by an on-board laser range finder URG-04LX. Then, the data is transformed to find the relevant information to the navigating process before being presented to a trained obstacle avoidance neural network which is optimized under the supervision of a Bayesian framework to find its structure and weight values.},
author = {Nguyen, Anh V. and Nguyen, Lien B. and Su, Steven and Nguyen, Hung T.},
doi = {10.1109/EMBC.2013.6610332},
file = {:C$\backslash$:/Users/tbaum/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen et al. - 2013 - The advancement of an obstacle avoidance Bayesian neural network for an intelligent wheelchair.pdf:pdf},
isbn = {9781457702167},
issn = {1557170X},
journal = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual Conference},
pages = {3642--3645},
pmid = {24110519},
title = {{The advancement of an obstacle avoidance Bayesian neural network for an intelligent wheelchair}},
volume = {2013},
year = {2013}
}
@article{Njah2013,
abstract = {Electric wheelchair is one of the most used for the movement of disabled and aged people. This work in- troduces an obstacle avoidance system aimed for provid- ing more autonomous navigation of a electric wheelchair (EW) in unknown indoor environments. These technolo- gies seek to increase the independence of people with dis- abilities and improve their quality of life by making the most of each individuals abilities. Furthermore, the in- tegration of an ultrasonic sensor to avoid obstacle and a fuzzy controller to generates velocity for aim to join the target position. A prototype of EW has been equipped with control unit based on two micro-controller. The first for manage the motors velocity. The second for explore the ultrasonic sensors. Two micro-controller exchanges the information with a PC board type PC104, which is used to process data from sensors and encoders. The information is processed by a control algorithm based on fuzzy logic. The control algorithm is optimized using the gradient method to min- imize the path traveled to reach the desired position. The practical implementation demonstrates the algorithm va- lidity for obstacle avoidance and goal achievement with a minimum path and greater security.},
annote = {FINAL CONCLUSIONS 

Fuzzy logic, which is the foremost influential concept of this paper is not applicable to our chair because of personal opinions of influential lab members. This paper will be good to use to explain why PID (a different control method which stands for proportional-integral-derivative controller) is better.

GENERAL NOTES

- Many gramatical errors in this paper; does this affect the validity of the paper?
- This paper has actual use of ultrasonic sensors for obstacle detection but does not integrate the use of ultrasonics with negative obstacle detection.},
author = {Njah, Malek and Jallouli, Mohamed},
file = {:C$\backslash$:/Users/tbaum/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Njah, Jallouli - 2013 - Wheelchair Obstacle Avoidance based on Fuzzy Controller and Ultrasonic Sensors.pdf:pdf},
isbn = {9781467352857},
journal = {IEEE Conference},
title = {{Wheelchair Obstacle Avoidance based on Fuzzy Controller and Ultrasonic Sensors}},
year = {2013}
}
@article{Ortigosa2011,
abstract = {The detection of surrounding obstacle-free space is an essential task for many intelligent automotive and robotic applications. In this paper we present a method to detect obstacle-free pathways in real-time using depth maps from a pair of stereo images. Depth maps are obtained by processing the disparity between left and right images from a stereo-vision system. The proposed technique assumes that depth of pixels in obstacle-free pathways should increase slightly and linearly from the bottom of the image to the top. The proposed real-time detection checkswhether the depth of groups of image columns matches a linear model. Only pixels fulfilling the matching requirements are identified as obstacle-free pathways. Experimental results with real outdoor stereo images show that the method performance is promising.},
author = {Ortigosa, Nuria and Morillas, Samuel and Peris-fajarn{\'{e}}s, Guillermo},
doi = {10.1007/s10846-010-9498-4},
file = {:C$\backslash$:/Users/tbaum/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ortigosa, Morillas, Peris-fajarn{\'{e}}s - 2011 - Obstacle-Free Pathway Detection by Means of Depth Maps.pdf:pdf},
journal = {J Intell Robot Syst},
keywords = {assisted navigation,depth map,pathway detection},
pages = {115--129},
title = {{Obstacle-Free Pathway Detection by Means of Depth Maps}},
volume = {63},
year = {2011}
}
@article{Rankin2007,
abstract = {Detecting negative obstacles (ditches, holes, wadis, and other depressions) is one of the most difficult problems in perception for unmanned ground vehicle (UGV) off-road autonomous navigation. One reason for this is that the width of the visible portion of a negative obstacle may only span a few pixels at the stopping distance for vehicle speeds UGV programs aspire to operate at (up to 50kph). The problem can be further compounded when negative obstacles are obscured by vegetation or when negative obstacles are embedded in undulating terrain. Because of the variety of appearances of negative obstacles, a multi-cue detection approach is desired. In previous nighttime negative obstacle detection work, we have described combining geometry based cues from stereo range data and a thermal signature based cue from thermal infrared imagery. Thermal signature is a powerful cue during the night since the interiors of negative obstacles generally remain warmer than surrounding terrain throughout the night. In this paper, we further couple the thermal signature based cue and geometry based cues from stereo range data for nighttime negative obstacle detection. Edge detection is used to generate closed contour candidate negative obstacle regions that are geometrically filtered to determine if they lie within the ground plane. Cues for negative obstacles from thermal signature, geometry-based analysis of range images, and geometry-based analysis of terrain maps are fused. The focus of this work is to increase the range at which UGVs can reliably detect negative obstacles on cross-country terrain, thereby increasing the speed at which UGVs can safely operate.},
annote = {FINAL CONCLUSIONS




GENERAL NOTES

{\textperiodcentered}        
The main method of obstacle detection in this
paper involves an integration with thermal signatures based on cues from
thermal infrared imagery along with geometry based cues from stereo range data.
This integration of topics seems to be frequently used in many of the papers
that have been published in the late 2000's and early 2010's for nighttime negative
obstacle detection. However, the reliance of a time-specific avoidance
technique is insufficient for a wheelchair which will be, most often, used
during the day. 
 

{\textperiodcentered}        
They utilized a traditional geometry-based
negative obstacle detection method that detects a gap followed by an upslope in
the range data. In order to determine which portions of the environment they
should analyze, they used edge detection in order to generate closed contour
regions that may contain negative obstacle cues. These location boundaries are
determined by areas where the second derivative crosses zero for the rectified
infrared intensity image. This increases the effectiveness of the algorithm and
reduces the need for unnecessary analysis of certain areas of the picture.
While this method of determining areas to analyze relies on thermal signatures,
it is a clever idea. We could try to find a way to determine which areas to
analyze that does not utilize the thermal signature. 
 

{\textperiodcentered}        
An important step in the determination of actual
negative obstacles versus false alarms involves shifting from a normalized
intensity difference image to a binary negative obstacle image. This step
functions through thresholding the intensity difference image with a determined
value. In this case, it is a value of 40. 
 

{\textperiodcentered}        
There are many more issues with the use of
thermal detection aside from the fact that it must be done at night. For
instance, the experiments must be completed after a relatively clear and sunny
day, not after rain or snow, etc. This leaves a lot of possible scenarios
untested.





t},
author = {Rankin, Arturo L and Huertas, Andres and Matthies, Larry H},
doi = {10.1117/12.720513},
file = {:C$\backslash$:/Users/tbaum/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rankin, Huertas, Matthies - 2007 - Nighttime negative obstacle detection for off-road autonomous navigation.pdf:pdf},
keywords = {autonomous navigation,negative obstacle detection,perception,stereo vision,thermal infrared},
number = {818},
pages = {1--12},
title = {{Nighttime negative obstacle detection for off-road autonomous navigation}},
volume = {6561},
year = {2007}
}
@article{Shang2015,
abstract = {Negative obstacles for field autonomous land vehicles (ALVs) refer to ditches, pits, or terrain with a negative slope, which will bring risks to vehicles in travel. This paper presents a feature fusion based algorithm (FFA) for negative obstacle detection with LiDAR sensors. The main contributions of this paper are fourfold: (1) A novel three-dimensional (3-D) LiDAR setup is presented.With this setup, the blind area around the vehicle is greatly reduced, and the density of LiDAR data is greatly improved, which are critical for ALVs. (2) On the basis of the proposed setup, a mathematical model of the point distribution of a single scan line is deduced, which is used to generate ideal scan lines. (3)With themathematicalmodel, an adaptivematching filter based algorithm (AMFA) is presented to implement negative obstacle detection. Features of simulated obstacles in each scan line are employed to detect the real negative obstacles. They are supposed to match with features of the potential real obstacles. (4) Grounded on AMFA algorithm, a feature fusion based algorithm is proposed. FFA algorithm fuses all the features generated by different LiDARs or captured at different frames. Bayesian rule is adopted to estimate the weight of each feature. Experimental results show that the performance of the proposed algorithm is robust and stable. Compared with the state-of-the-art techniques, the detection range is improved by 20{\%}, and the computing time is reduced by an order of two magnitudes. The proposed algorithm had been successfully applied on two ALVs, which won the champion and the runner-up in the “Overcome Danger 2014” ground unmanned vehicle challenge of China.},
annote = {FINAL CONCLUSIONS




GENERAL NOTES

{\textperiodcentered}        
This method incorporates a unique setup of 3
LIDAR cameras arranged so that the ALV can see around the entire vehicle.
Traditionally, three-dimensional LiDARs were usually equipped upright on the vehicle
roof; this created drawbacks including a large blind spot around the vehicle
which is dangerous for off-road travel, and as the sensor head spins, each
laser horizontally generates high density points, but the spacing between the
scan lines increases dramatically as the distance from the sensor increases
which makes detecting smaller obstacles almost impossible. The unique set-up
involves 2 LIDARS angled downward, one on the left, one on the right, and then
another LIDAR placed directly on the top of the car. This dramatically reduces
the blind region of the car and increases the scan density in the area of
interest. 
 


{\textperiodcentered}        
The algorithm in use for negative obstacle
detection is called feature fusion based algorithm (FFA). This algorithm's
effectiveness was tested against the adaptive matching filter based algorithm
(AMFA). The AMFA algorithm has many faults: it gives false alarms in complex
environments, is affected seriously with LIDAR sensor failures, and has low
efficiency of independent obstacle location fusion. The use of this adapted
algorithm proved to improve the accuracy of negative obstacle detection by 20{\%},
(it can detect much smaller ditches than the AMFA algorithm) and its computing
time is 10 ms instead of 100 ms for the AMFA algorithm. 
 

{\textperiodcentered}        
This algorithm was used in the “Overcome Danger
2014” ground unmanned vehicle challenge of China and finished as the runner-up
finishing with a score of negative obstacle detection task of 14.4{\%}. 
 


{\textperiodcentered}        
False alarms with the FFA algorithm still occur,
however they are less frequent than the AMFA algorithm. The false alarms
generated by this algorithm did not bring trouble to the ALVs in testing when
driving autonomously. 
 


{\textperiodcentered}        
The biggest stride with this research is the
real-time implementation of the obstacle detection capabilities. All
distributing processing in the ALV's must be real-time capable for obvious
reasons.},
author = {Shang, Erke and An, Xiangjing and Wu, Tao and Hu, Tingbo and Yuan, Qiping and He, Hangen},
doi = {10.1002/rob},
file = {:C$\backslash$:/Users/tbaum/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shang et al. - 2015 - LiDAR based negative obstacle detection for field autonomous land vehicles.pdf:pdf},
journal = {Journal of Field Robotics},
number = {0},
pages = {1--27},
title = {{LiDAR based negative obstacle detection for field autonomous land vehicles}},
volume = {00},
year = {2015}
}
@article{Larson2011,
abstract = {In order for an autonomous unmanned ground vehicle (UGV) to drive in off-road terrain at high speeds, it must analyze and understand its surrounding terrain in realtime: it must know where it intends to go, where are the hazards, and many details of the topography of the terrain. Much research has been done in the way of obstacle avoidance, terrain classification, and path planning, but still so few UGV systems can accurately traverse off-road environments at high speeds autonomously. One of the most dangerous hazards found off-road are negative obstacles, mainly because they are so difficult to detect. We present algorithms that analyze the terrain using a point cloud produced by a 3D laser range finder, then attempt to classify the negative obstacles using both a geometry-based method we call the Negative Obstacle DetectoR (NODR) as well as a support vector machine (SVM) algorithm. The terrain is analyzed with respect to a large UGV with the sensor mounted up high as well as a small UGV with the sensor mounted low to the ground.},
annote = {FINAL CONCLUSIONS





GENERAL NOTES

{\textperiodcentered}        
This paper presents a method for obstacle
detection that uses a 3D laser finder. The 3D laser range finder creates a
point cloud. Once this point cloud is created, an attempt is made to classify
negative obstacles using a geometry-based method they call Negative Obstacle
DetectoR (NODR) along with a support vector machine (SVM) algorithm. The
placement of the large sensor is mounted high on the top of the ALV, while the
placement of the smaller sensor is mounted low to the ground. 
 

{\textperiodcentered}        
This method focuses on two distinct algorithms
(the SVM and NODR algorithms) that each have specific functions. The SVM
algorithm is for short-range detection while the NODR is for long range
detection. 
 


{\textperiodcentered}        
The applications of this research pertain to
military grade autonomous vehicles which must be able to travel at high speeds
with high obstacle detection accuracy. In our case, it is unnecessary to have
algorithms that can function at high speeds effectively. The small vehicle they
used, which is more applicable to research on our wheelchair could travel at
2.5 m/s and process the data in .5 s in order to stop 2.2 m away. 
 

{\textperiodcentered}        
The LiDAR seemed to collect extremely accurate
data, collecting readings of range and intensity out to a distance of 120
meters with 80{\%} reflectivity, providing 100,000 data points with 360 degrees
horizontal and 26.8 degrees vertical field of view at a rate of 10 Hz. * Is
there any way that we can also use the LiDAR that is on the top of the vehicle
for obstacle detection, in addition to the PING sensors?},
author = {Larson, Jacoby and Trivedi, Mohan},
doi = {10.1109/ITSC.2011.6083105},
file = {:C$\backslash$:/Users/tbaum/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Larson, Trivedi - 2011 - Lidar based off-road negative obstacle detection and analysis.pdf:pdf},
isbn = {9781457721984},
issn = {2153-0009},
journal = {IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC},
pages = {192--197},
title = {{Lidar based off-road negative obstacle detection and analysis}},
year = {2011}
}
@article{Hofmann2013,
abstract = {Driving cross-country, the detection and state estimation relative to negative obstacles like ditches and creeks is mandatory for safe operation. Very often, ditches can be detected both by different photometric properties (soil vs. vegetation) and by range (disparity) discontinuities. Therefore, algorithms should make use of both the photometric and geometric properties to reliably detect obstacles. This has been achieved in UBM's EMS-vision system (Expectation-based, Multifocal, Saccadic) for autonomous vehicles. The perception system uses Sarnoff's image processing hardware for real-time stereo vision. This sensor provides both gray value and disparity information for each pixel at high resolution and framerates. In order to perform an autonomous jink, the boundaries of an obstacle have to be measured accurately for calculating a safe driving trajectory. Especially, ditches are often very extended, so due to the restricted field of vision of the cameras, active gaze control is necessary to explore the boundaries of an obstacle. For successful measurements of image features the system has to satisfy conditions defined by the perception expert. It has to deal with the time constraints of the active camera platform while performing saccades and to keep the geometric conditions defined by the locomotion expert for performing a jink. Therefore, the experts have to cooperate. This cooperation is controlled by a central decision unit (CD), which has knowledge about the mission and the capabilities available in the system and of their limitations. The central decision unit reacts dependent on the result of situation assessment by starting, parameterizing or stopping actions (instances of capabilities). The approach has been tested with the 5-ton van VaMoRs. Experimental results will be shown for driving in a typical off-road scenario.},
annote = {FINAL CONCLUSIONS

GENERAL NOTES

{\textperiodcentered}        
This negative obstacle avoidance method is
described as an EMS-Vision System (Expectation-based, Multifocal, Saccadic).
This system's image processing creates a real-time stereo vision; the active gaze
control allows for the sensor's analysis of its surroundings to be dynamic, and
the saccades of the camera keep the geometric conditions defined. 
 


{\textperiodcentered}        
Because this study focused on off-road
conditions, this method emphasizes the necessity of a system that perceives
photometric properties (soil vs. vegetation) and range (disparity)
discontinuities. (Detection of range discontinuities will be the main method
behind the wheelchair's negative obstacle detection because PING sensors do not
have the capability of distinguishing between vegetation and soil.) The
EMS-Vision System relies on both of these readings in order to distinguish
between shadows and actual ditches and pits. 
 

{\textperiodcentered}        
In physical experimentation of the method, an
ALV was able to effectively maneuver around a negative obstacle. To ensure
accurate negative obstacle detection, the cameras have to confirm for 15 cycles
of analysis that the ditch actually exists. Once this occurs, a hypothesis of
the ditch position is published, and the vehicle stops. Then the vehicle
performs saccades until the boundaries are determined. It chooses a direction
to move in order to avoid the obstacle, and performs saccades in that direction
as it moves until the obstacle is avoided, and therefore becomes irrelevant. This
entire process is an application of active gaze control. 
 

{\textperiodcentered}        
In order to avoid false alarms, a 4-D approach
for tracking of object hypotheses is used, but not significantly discussed.


{\textperiodcentered}        
They implement the concept of a look ahead
region (LAR). The LAR is defined as the maximum region where an environmental
feature with a definite size or depth can be measured. This distance depends
directly on the speed on the wheelchair. An important assertion this group made
was that if the LAR possible is smaller than the LAR necessary for safe use,
the vehicle must slow down. 
 

{\textperiodcentered}        
This group created an effective method of
negative obstacle detection for off-road travel. This method, however, is quite
expensive and specific to off-road terrain.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Hofmann, Ulrich and Siedersberger, Karl-heinz},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/tbaum/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hofmann, Siedersberger - 2013 - Stereo and photometric image sequence interpretation for detecting negative obstacles using active gaze.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
journal = {Journal of Chemical Information and Modeling},
keywords = {icle},
number = {9},
pages = {1689--1699},
pmid = {25246403},
title = {{Stereo and photometric image sequence interpretation for detecting negative obstacles using active gaze control and performing an autonomous jink}},
volume = {53},
year = {2013}
}
@article{Hu2011,
abstract = {Negative obstacle detection has been a challenging topic. In the previous researches, the distance that negative obstacles can be detected is so near that vehicles have to travel at a very low speed. In this paper, a negative obstacle detection algorithm from image sequences is proposed. When negative obstacles are far from the vehicle, color appearance models are used as the cues of detecting negative obstacles, while negative obstacles get closer, geometrical cues are extracted from stereo vision. Furthermore, different cues are combined in a Bayesian framework to detect obstacles in image sequences. Massive experiments show that the proposed negative obstacle detection algorithm is quite effective. The alarming distance for 0.8 m width negative obstacle is 18m, and the confirming distance is 10 m. This supplies more space for vehicles to slow down and avoid obstacles. Then, the security of the UGV running in the field can be improved remarkably.},
annote = {FINAL CONCLUSIONS


GENERAL NOTES

- The methodology here implements an integration
of color appearance models for obstacles that are quite far away and
geometrical cues for obstacles that are closer. Different cues are combined
through a Bayesian framework to detect obstacles in image sequences. This
algorithm allows for more reaction time for the ALV to slow down and stop or
avoid obstacles. 

- Negative obstacle cues from color appearance
analyze 2D images. Commonly, ditches or pits, from far away, are represented as
dark regions on the ground with obviously horizontal edges. This paper uses one
of the many available color tracking algorithms which can detect dark regions;
the specific algorithm in use is irrelevant. 

- As a negative obstacle gets closer, occlusion
can be detected with stereo vision. Once this happens, the occlusion is
categorized. If the obstacle is determined to be a negative obstacle, the trailing
wall can be tracked and the bottom of the can be determined by applying the height
threshold. 
 

- The effectiveness of this algorithm is generally
described with no real justification, therefore, the theories can be considered
but should not be relied on.},
author = {Hu, Tingbo and Nie, Yiming and Wu, Tao and He, Hangen},
doi = {10.1117/12.896288},
file = {:C$\backslash$:/Users/tbaum/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu et al. - 2011 - Negative obstacle detection from image sequences.pdf:pdf},
isbn = {0819485837, 9780819485830},
journal = {Proceedings of SPIE},
keywords = {Bayesian framework,Negative obstacle detection,image sequence,occlusion detection,stereo vision},
number = {1},
pages = {1--7},
title = {{Negative obstacle detection from image sequences}},
volume = {8009},
year = {2011}
}
@article{Fazli2011,
abstract = {Though a significant amount of work has been done on detecting obstacles, not much attention has been given to the detection of drop offs, e.g., sidewalk curbs, downward stairs, and other hazards. In this paper, we propose algorithms for detecting negative obstacles in an urban setting using stereo vision and two-stage dynamic programming (TSDP) technique. We are developing computer vision algorithms for sensing important terrain features as an aid to blind navigation, which interpret visual information obtained from images collected by cameras mounted on camera legs nearly as high as young person. This paper focuses specifically on a novel computer vision algorithm for detecting negative obstacles (i.e. anything below the level of the ground, such as holes and drop-offs), which are important and ubiquitous features on and near sidewalks and other walkways. The proposed algorithm is compared to other algorithms such as belief propagation and random growing correspondence seeds (GCS). According to the results, the proposed method achieves higher speed, more accurate disparity map and lower RMS errors. The speed of the proposed algorithm is about 28{\%} higher than the random GCS algorithm. We demonstrate experimental results on typical sidewalk scenes to show the effectiveness of the proposed method. {\#}},
author = {Fazli, Saeid and {Dehnavi, Hajar Mohammadi Moallem}, Payman},
file = {:C$\backslash$:/Users/tbaum/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fazli, Dehnavi, Hajar Mohammadi Moallem - 2011 - A Robust Negative Obstacle Detection Method Using Seed-Growing and Dynamic Programming.pdf:pdf},
journal = {Optical Review},
keywords = {blind navigation,negative obstacle,obstacle detection,stereo matching,visually impaired},
number = {6},
pages = {415--422},
title = {{A Robust Negative Obstacle Detection Method Using Seed-Growing and Dynamic Programming for Visually-Impaired / Blind Persons}},
volume = {18},
year = {2011}
}
@article{Nguyen2013a,
abstract = {This paper is concerned with the experimental study performance of a smart wheelchair system named TIM (Thought-controlled Intelligent Machine), which uses a unique camera configuration for vision. Included in this configuration are stereoscopic cameras for 3-Dimensional (3D) depth perception and mapping ahead of the wheelchair, and a spherical camera system for 360-degrees of monocular vision. The camera combination provides obstacle detection and mapping in unknown environments during real-time autonomous navigation of the wheelchair. With the integration of hands-free wheelchair control technology, designed as control methods for people with severe physical disability, the smart wheelchair system can assist the user with automated guidance during navigation. An experimental study on this system was conducted with a total of 10 participants, consisting of 8 able-bodied subjects and 2 tetraplegic (C-6 to C-7) subjects. The hands-free control technologies utilized for this testing were a head-movement controller (HMC) and a brain-computer interface (BCI). The results showed the assistance of TIM's automated guidance system had a statistically significant reduction effect (p-value = 0.000533) on the completion times of the obstacle course presented in the experimental study, as compared to the test runs conducted without the assistance of TIM.},
annote = {NULL},
author = {Nguyen, Jordan S. and Su, Steven W. and Nguyen, Hung T.},
doi = {10.1109/EMBC.2013.6610571},
file = {:C$\backslash$:/Users/tbaum/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen, Su, Nguyen - 2013 - Experimental study on a smart wheelchair system using a combination of stereoscopic and spherical vision.pdf:pdf},
isbn = {9781457702167},
issn = {1557170X},
journal = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual Conference},
pages = {4597--4600},
pmid = {24110758},
title = {{Experimental study on a smart wheelchair system using a combination of stereoscopic and spherical vision}},
volume = {2013},
year = {2013}
}
@article{Ghani2017,
author = {Ghani, Muhammad Fahmi Abdul and Sahari, Khairul Salleh Mohamed},
doi = {10.1177/1729881417710972},
file = {:C$\backslash$:/Users/tbaum/Downloads/now2.pdf:pdf},
issn = {1729-8814},
journal = {International Journal of Advanced Robotic Systems},
keywords = {17 march 2016,28 march 2017,accepted,date received,mapping,microsoft kinect,mobile robotics,obstacle detection,special issue - robotic,technology for sustainable humanity,topic},
number = {3},
pages = {172988141771097},
title = {{Detecting negative obstacle using Kinect sensor}},
url = {http://journals.sagepub.com/doi/10.1177/1729881417710972},
volume = {14},
year = {2017}
}
@article{Wang2016,
author = {Wang, Jian and Song, Qian and Jiang, Zhibiao and Zhou, Zhimin},
file = {:C$\backslash$:/Users/tbaum/Downloads/now3.pdf:pdf},
isbn = {9781509033324},
pages = {1174--1177},
title = {{A novel insar based off ­ road positive and negative obstacle detection technique for unmanned ground vechicle}},
year = {2016}
}
@book{Mcmanamon2015,
address = {Bellingham, Washington},
author = {Mcmanamon, Paul},
edition = {SPIE Field},
editor = {Greivenkamp, John E.},
file = {:C$\backslash$:/Users/tbaum/Downloads/9781628416558.pdf:pdf},
isbn = {9781628416541},
pages = {1--171},
publisher = {SPIE Press},
title = {{Field Guide to Lidar}},
url = {http://spie.org},
year = {2015}
}
